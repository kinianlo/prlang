{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kinianlo/prlang/blob/main/archive/prep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6629c529-f711-44a1-9f77-8b94484b503f"
      },
      "source": [
        "# PR-like models in langauge\n"
      ],
      "id": "6629c529-f711-44a1-9f77-8b94484b503f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb7b9c91-4e6e-457d-bad3-0c283adef49b"
      },
      "source": [
        "### Generate PR-like models with Masked LM "
      ],
      "id": "cb7b9c91-4e6e-457d-bad3-0c283adef49b"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7NFno-CfRPW",
        "outputId": "7c988967-6751-4176-88f3-f4d19187d07d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/kinianlo/contextuality.git\n",
            "  Cloning https://github.com/kinianlo/contextuality.git to /tmp/pip-req-build-l90s2elh\n",
            "  Running command git clone -q https://github.com/kinianlo/contextuality.git /tmp/pip-req-build-l90s2elh\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.7/dist-packages (2.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.2)\n",
            "Requirement already satisfied: picos in /usr/local/lib/python3.7/dist-packages (from Contextuality==0.0.1) (2.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: cvxopt in /usr/local/lib/python3.7/dist-packages (from picos->Contextuality==0.0.1) (1.2.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy inflect torch transformers git+https://github.com/kinianlo/contextuality.git"
      ],
      "id": "f7NFno-CfRPW"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "2933c683-18fb-48c9-9832-1adb0fd3a595"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import numpy as np\n",
        "import inflect\n",
        "import random\n",
        "import json\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "from time import time\n",
        "\n",
        "from contextuality.model import Model, CyclicScenario\n",
        "\n",
        "import torch\n",
        "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
        "from transformers import logging\n",
        "logging.set_verbosity_error()"
      ],
      "id": "2933c683-18fb-48c9-9832-1adb0fd3a595"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "2e0d0f08-5645-49f0-990c-e0355e7cc9d1"
      },
      "outputs": [],
      "source": [
        "def get_probs(sentences_raw, options, model, tokenizer, mask_placeholder='_'):\n",
        "    \"\"\"\n",
        "    Predict a masked word with probability scores for the provided options\n",
        "    for the mask.\n",
        "    \n",
        "    Parameters\n",
        "    ---------\n",
        "    sentences_raw : str or (list of str)\n",
        "    options : (list of str) or (list of (list of str))\n",
        "    model : MaskedLM\n",
        "    tokenizer : Tokenizer\n",
        "    \"\"\"\n",
        "    torch.cuda.empty_cache()\n",
        "    if type(sentences_raw) is str:\n",
        "        sentences_raw = [sentences_raw]\n",
        "    if type(options[0]) is str:\n",
        "        options = [options for s in sentences_raw]\n",
        "    \n",
        "    partition_size = 2**8\n",
        "    n_sentence = len(sentences_raw)\n",
        "    if n_sentence > partition_size:\n",
        "        print(f\"Processing {n_sentence} sentences. Batching...\")\n",
        "        probs = []\n",
        "        for i in tqdm(range(0, len(sentences_raw), partition_size)):\n",
        "            sentences_raw_part = sentences_raw[i:i+partition_size]\n",
        "            options_part = options[i:i+partition_size]\n",
        "            probs += get_probs(sentences_raw_part, options_part, model,\n",
        "                               tokenizer, mask_placeholder=mask_placeholder)\n",
        "        return probs\n",
        "        \n",
        "    # Convert the option words into tokens\n",
        "    options_token = [[tokenizer.tokenize(op)[0] for op in ops] for ops in options]\n",
        "    options_id = [[tokenizer.vocab[op] for op in ops] for ops in options_token]\n",
        "    \n",
        "    # Replace mask placeholders with the mask token used by the given tokenizer\n",
        "    sentences = [s.replace(mask_placeholder, tokenizer.mask_token) for s in sentences_raw]\n",
        "    inputs = tokenizer(sentences, return_tensors='pt', padding=True).to(model.device)\n",
        "    \n",
        "    mask_indices = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)\n",
        "    \n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    \n",
        "    mask_logits = logits[mask_indices]\n",
        "    \n",
        "    probs = [[] for i in range(len(sentences))]\n",
        "    \n",
        "    for i in range(len(mask_indices[0])):\n",
        "        s_idx, m_idx = mask_indices[0][i], mask_indices[1][i]\n",
        "        prob = torch.softmax(mask_logits[i][options_id[s_idx]], dim=-1).detach().cpu().numpy()\n",
        "        prob = dict(zip(options[s_idx], prob))\n",
        "        probs[s_idx] = prob\n",
        "        \n",
        "    if len(probs) == 1:\n",
        "        probs = probs[0]\n",
        "    return probs"
      ],
      "id": "2e0d0f08-5645-49f0-990c-e0355e7cc9d1"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "ec4c356f-44a6-4632-be22-7ed614646a41"
      },
      "outputs": [],
      "source": [
        "# Initialise the language model and its tokenizer\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "lm_name = 'bert-base-uncased'\n",
        "mlm = AutoModelForMaskedLM.from_pretrained(lm_name).to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(lm_name)"
      ],
      "id": "ec4c356f-44a6-4632-be22-7ed614646a41"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b95fc7ea-6116-4cb3-ac11-b41ff650b079"
      },
      "source": [
        "## The following handles a batch of examples\n",
        "Examples should be given in a text file where each row has the format:\n",
        "\n",
        "```outcome1 outcome2: observable1 observable2 observable3 observable4 ...```\n",
        "\n",
        "For example,\n",
        "\n",
        "```apple strawberry: sweet red round green big```\n",
        "\n",
        "For each row, all ordered combinations of 3 observables will be considered in the following."
      ],
      "id": "b95fc7ea-6116-4cb3-ac11-b41ff650b079"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "f165005e-8037-481b-a4e0-cdbfe4ddb9d1"
      },
      "outputs": [],
      "source": [
        "def process_topics_file(file_name):\n",
        "    topics = []\n",
        "    with open(file_name) as file:\n",
        "        for row in file:\n",
        "            if not row.strip():\n",
        "                continue\n",
        "            outcomes = [] \n",
        "            observables = []\n",
        "            outcomes_str, observables_str = map(str.strip, row.split(':'))\n",
        "            outcomes = list(map(str.strip, set(outcomes_str.split(','))))\n",
        "            observables = list(map(str.strip, set(observables_str.split(','))))\n",
        "            topics.append((outcomes, observables))\n",
        "    return topics\n",
        "\n",
        "def process_schemas_file(file_name):\n",
        "    schema_options = dict()\n",
        "    schemas = dict()\n",
        "    with open(file_name) as file:\n",
        "        data = json.load(file)\n",
        "        schema_options = data['options']\n",
        "        schemas = data['schemas']\n",
        "    return schema_options, schemas"
      ],
      "id": "f165005e-8037-481b-a4e0-cdbfe4ddb9d1"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "e3a66551-dc12-4050-ad3a-dd8d8d093bc4"
      },
      "outputs": [],
      "source": [
        "def generate_scenarios(topics, schema=None):\n",
        "    scenarios = []\n",
        "    for topic in topics:\n",
        "        outcomes, observables = topic\n",
        "        out_perm = itertools.permutations(outcomes, 2)\n",
        "        obs_perm = itertools.permutations(observables, 3)\n",
        "        scenarios += list(itertools.product(out_perm, obs_perm))\n",
        "    return scenarios"
      ],
      "id": "e3a66551-dc12-4050-ad3a-dd8d8d093bc4"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "c0df2481-7e25-4cc5-9ed2-d5d64905f43a"
      },
      "outputs": [],
      "source": [
        "def a(word):\n",
        "    \"\"\"Return `a` or `an` depending on the given word.\n",
        "    \"\"\"\n",
        "    return inflect.engine().a(word)\n",
        "\n",
        "def generate_sentences(scenario, schema):\n",
        "    sentences = []\n",
        "    o, x = scenario\n",
        "    if schema == 'adj':\n",
        "        intro = f\"There is {a(o[0])} and {a(o[1])}.\"\n",
        "        sentences.append(f\"{intro} The _ is {x[0]} and the same one is {x[1]}.\")\n",
        "        sentences.append(f\"{intro} The _ is {x[1]} and the same one is {x[2]}.\")\n",
        "        sentences.append(f\"{intro} The _ is {x[2]} and the other one is {x[0]}.\")\n",
        "    elif schema == 'verb':\n",
        "        intro = f\"There is {a(o[0])} and {a(o[1])}.\"\n",
        "        sentences.append(f\"{intro} The _ is being {x[0]} and the same one is being {x[1]}.\")\n",
        "        sentences.append(f\"{intro} The _ is being {x[1]} and the same one is being {x[2]}.\")\n",
        "        sentences.append(f\"{intro} The _ is being {x[2]} and the other one is being {x[0]}.\")\n",
        "    elif schema == 'prep':\n",
        "        intro = f\"There is {a(o[0])} and {a(o[1])}.\"\n",
        "        sentences.append(f\"{intro} The _ is {x[0]} and the same one is {x[1]}.\")\n",
        "        sentences.append(f\"{intro} The _ is {x[1]} and the same one is {x[2]}.\")\n",
        "        sentences.append(f\"{intro} The _ is {x[2]} and the other one is {x[0]}.\")\n",
        "    return sentences\n",
        "\n",
        "def get_mask_options(scenario, schema):\n",
        "    o, x = scenario\n",
        "    return [o for i in range(3)]"
      ],
      "id": "c0df2481-7e25-4cc5-9ed2-d5d64905f43a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ac4eff3-3199-449d-843f-900ba47643ab"
      },
      "source": [
        "# Load topics files here!\n"
      ],
      "id": "7ac4eff3-3199-449d-843f-900ba47643ab"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_o-3RK_pm0S",
        "outputId": "551fe632-363c-4399-b53a-e9d80f228aec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root\n",
            "Cloning into 'prlang'...\n",
            "remote: Enumerating objects: 109, done.\u001b[K\n",
            "remote: Counting objects: 100% (109/109), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 109 (delta 54), reused 57 (delta 19), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (109/109), 191.99 KiB | 6.86 MiB/s, done.\n",
            "Resolving deltas: 100% (54/54), done.\n",
            "/root/prlang\n"
          ]
        }
      ],
      "source": [
        "%cd\n",
        "%rm -rf prlang\n",
        "!git clone https://github.com/kinianlo/prlang.git\n",
        "%cd prlang"
      ],
      "id": "8_o-3RK_pm0S"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1617f7f-4c69-4402-bd98-68c9732bf359",
        "outputId": "b2b6f241-4a89-4512-cd75-dfff21083bdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topics for schema `prep`:\n",
            "(['apple', 'strawberry'], ['in a dish', 'in the fridge', 'on the table'])\n",
            "(['girl', 'boy'], ['across the street', 'on a bus', 'in the city', 'near the shop', 'from the town', 'at the school'])\n"
          ]
        }
      ],
      "source": [
        "topics = process_topics_file('data/prep.txt')\n",
        "schema = 'prep'\n",
        "\n",
        "print(f'Topics for schema `{schema}`:')\n",
        "for t in topics:\n",
        "    print(t)"
      ],
      "id": "f1617f7f-4c69-4402-bd98-68c9732bf359"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518,
          "referenced_widgets": [
            "063a30831d0846c2a30106ffb6c926bc",
            "df258f8e02a34aa9828e79a8f76cbb0a",
            "5c7e31ec78c9434caae3cc0f8240655b",
            "ac7b1dc80dca4df6babadb71dd3e50e4",
            "93f4c83c284a48b29d038ca8f8d5cf8d",
            "d5a896e20b84461e8b7557280441c095",
            "28f8b528248f4e8bbf9d574363f67886",
            "9171e3f8b59748709bb3270ecdecb52a",
            "4cce5931a70c4f9a91b6046cb7b11331",
            "1adda4f9f5c245f88f29af431e8f6d36",
            "acc4bc9cb2364046ab6aa03664fbb9b3"
          ]
        },
        "id": "1778c5cb-d6cb-46ef-be5e-7ce8d6c99791",
        "outputId": "2b38ed56-832c-48e7-ec1b-d8056ceef60e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Curent topic: (['apple', 'strawberry'], ['in a dish', 'in the fridge', 'on the table'])\n",
            "Number of scenarios: 12\n",
            "There is an apple and a strawberry. The _ is on the table and the same one is in the fridge.\n",
            "There is an apple and a strawberry. The _ is in the fridge and the same one is in a dish.\n",
            "There is an apple and a strawberry. The _ is in a dish and the other one is on the table.\n",
            "                              (0, 0) (0, 1) (1, 0) (1, 1)\n",
            "(on the table, in the fridge) 0.5591 0.0000 0.0000 0.4409\n",
            "(in the fridge, in a dish) 0.5640 0.0000 0.0000 0.4360\n",
            "(in a dish, on the table) 0.0000 0.4778 0.5222 0.0000\n",
            "\n",
            "Signalling fraction: 0.12791317666402535\n",
            "\\model{apple}{strawberry}{on the table}{in the fridge}{in a dish}{0.5590721368789673}{0.563956618309021}{0.4777790307998657}\n",
            "============================================================\n",
            "Curent topic: (['girl', 'boy'], ['across the street', 'on a bus', 'in the city', 'near the shop', 'from the town', 'at the school'])\n",
            "Number of scenarios: 240\n",
            "Processing 720 sentences. Batching...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "063a30831d0846c2a30106ffb6c926bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There is a girl and a boy. The _ is across the street and the same one is on a bus.\n",
            "There is a girl and a boy. The _ is on a bus and the same one is at the school.\n",
            "There is a girl and a boy. The _ is at the school and the other one is across the street.\n",
            "                                   (0, 0) (0, 1) (1, 0) (1, 1)\n",
            "(across the street, on a bus) 0.5725 0.0000 0.0000 0.4275\n",
            "(on a bus, at the school) 0.5274 0.0000 0.0000 0.4726\n",
            "(at the school, across the street) 0.0000 0.4996 0.5004 0.0000\n",
            "\n",
            "Signalling fraction: 0.14496433650797913\n",
            "\\model{girl}{boy}{across the street}{on a bus}{at the school}{0.5724821090698242}{0.5273512601852417}{0.49956968426704407}\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame(columns=['nouns', 'modifiers', 'models', 'contextual_models'])\n",
        "\n",
        "sfs_list = []\n",
        "sheaf_models_list = []\n",
        "\n",
        "for topic in topics:\n",
        "    row = dict()\n",
        "    scenarios = generate_scenarios([topic], schema)\n",
        "    print(f\"Curent topic: {topic}\")\n",
        "    row['nouns'], row['modifiers'] = topic\n",
        "\n",
        "    n_scenario = len(scenarios)\n",
        "    row['models'] = n_scenario\n",
        "    print(f\"Number of scenarios: {n_scenario}\")\n",
        "    \n",
        "    sentences = [generate_sentences(scen, schema) for scen in scenarios]\n",
        "    sentences_flat = list(itertools.chain.from_iterable(sentences))\n",
        "\n",
        "    mask_options = [get_mask_options(scen, schema) for scen in scenarios]\n",
        "    mask_options_flat = list(itertools.chain.from_iterable(mask_options))\n",
        "\n",
        "    probs_flat = get_probs(sentences_flat, mask_options_flat, mlm, tokenizer)\n",
        "    probs = [probs_flat[3*i:3*i+3] for i in range(n_scenario)]\n",
        "\n",
        "    sheaf_models = []\n",
        "    cbd_models = []\n",
        "    sfs = []\n",
        "    cbds = []\n",
        "    for i in range(n_scenario):\n",
        "        outcomes, observables = scenarios[i]\n",
        "        tri_scenario = CyclicScenario(observables, 2)\n",
        "        o0, o1 = outcomes\n",
        "        x0, x1, x2 = observables\n",
        "        \n",
        "        table = []\n",
        "        table.append([probs[i][0][o0], 0, 0, probs[i][0][o1]])\n",
        "        table.append([probs[i][1][o0], 0, 0, probs[i][1][o1]])\n",
        "        table.append([0, probs[i][2][o0], probs[i][2][o1], 0])\n",
        "        \n",
        "        model = Model(tri_scenario, table)\n",
        "        sfs.append(model.signalling_fraction())\n",
        "        cbds.append(model.CbD_measure())\n",
        "        if sfs[-1] < 1/6:\n",
        "            sheaf_models.append(model)\n",
        "            for s in sentences[i]:\n",
        "                print(s)\n",
        "            print(model)\n",
        "            print(f\"Signalling fraction: {model.signalling_fraction()}\")\n",
        "            print(f\"\\\\model{{{o0}}}{{{o1}}}{{{x0}}}{{{x1}}}{{{x2}}}{{{probs[i][0][o0]}}}{{{probs[i][1][o0]}}}{{{probs[i][2][o0]}}}\")\n",
        "            print('='*60)\n",
        "        \n",
        "        if cbds[-1] > 0:\n",
        "            cbd_models.append(model)\n",
        "    sheaf_models_list += sheaf_models\n",
        "    sfs_list += sfs\n",
        "    row['contextual_models'] = len(sheaf_models)\n",
        "    df = df.append(row, ignore_index=True)"
      ],
      "id": "1778c5cb-d6cb-46ef-be5e-7ce8d6c99791"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "4d273715-5ffc-4a39-9b02-9c9806accc55",
        "outputId": "2b5189ff-c305-46f5-d1b0-c93d1581146e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 nouns                                          modifiers  \\\n",
              "0  [apple, strawberry]           [in a dish, in the fridge, on the table]   \n",
              "1          [girl, boy]  [across the street, on a bus, in the city, nea...   \n",
              "\n",
              "  models contextual_models  \n",
              "0     12                 1  \n",
              "1    240                 1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-949efb14-366d-4f4c-aa9f-ad46b6a09221\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nouns</th>\n",
              "      <th>modifiers</th>\n",
              "      <th>models</th>\n",
              "      <th>contextual_models</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[apple, strawberry]</td>\n",
              "      <td>[in a dish, in the fridge, on the table]</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[girl, boy]</td>\n",
              "      <td>[across the street, on a bus, in the city, nea...</td>\n",
              "      <td>240</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-949efb14-366d-4f4c-aa9f-ad46b6a09221')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-949efb14-366d-4f4c-aa9f-ad46b6a09221 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-949efb14-366d-4f4c-aa9f-ad46b6a09221');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "df"
      ],
      "id": "4d273715-5ffc-4a39-9b02-9c9806accc55"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "EQvtlHZ_w67O",
        "outputId": "a2d7754a-4106-4fad-a80c-4a9b4da67598"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total number of scenarios: 252.\n",
            "total number sheaf-contextual scenarios: 2(0.79%).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\histogram{(0.0000, 0) (0.0417, 0) (0.0833, 0) (0.1250, 2) }{(0.1667, 0) (0.2083, 5) (0.2500, 13) (0.2917, 19) (0.3333, 15) (0.3750, 36) (0.4167, 34) (0.4583, 12) (0.5000, 42) (0.5417, 20) (0.5833, 20) (0.6250, 31) (0.6667, 0) (0.7083, 0) (0.7500, 2) (0.7917, 1) (0.8333, 0) (0.8750, 0) (0.9167, 0) (0.9583, 0) }\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "print(f\"total number of scenarios: {len(sfs_list)}.\")\n",
        "print(f\"total number sheaf-contextual scenarios: {len(sheaf_models_list)}({len(sheaf_models_list)/len(sfs_list)*100:.2f}%).\")\n",
        "plt.hist(sfs_list, bins=24)\n",
        "\n",
        "plt.xlim((0,1))\n",
        "plt.title(\"Signalling fractions from language examples.\")\n",
        "plt.show()\n",
        "\n",
        "freq, edge = np.histogram(sfs_list, range=(0, 1), bins=24)\n",
        "out1 = ''\n",
        "out2 = ''\n",
        "for f, e in zip(freq, edge[:-1]):\n",
        "    if e < 1/6-1e-5:\n",
        "        out1 += f\"({e:.4f}, {f}) \"\n",
        "    else:\n",
        "        out2 += f\"({e:.4f}, {f}) \"\n",
        "print(f'\\\\histogram{{{out1}}}{{{out2}}}')"
      ],
      "id": "EQvtlHZ_w67O"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "ynGX7bFDUEjL"
      },
      "outputs": [],
      "source": [
        "# print(f\"total number of scenarios: {len(cbds)}.\")\n",
        "# plt.hist(cbds, bins=50)\n",
        "\n",
        "# plt.title(\"CbD from language examples.\")\n",
        "# plt.show()"
      ],
      "id": "ynGX7bFDUEjL"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "NvbS5hsCU-wS"
      },
      "outputs": [],
      "source": [
        "# print(cbd_models[0])\n",
        "# print(cbd_models[0].CbD_measure())"
      ],
      "id": "NvbS5hsCU-wS"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "tHJZK4HX73rk"
      },
      "outputs": [],
      "source": [
        "# from contextuality.model import random_pr_like_model\n",
        "# random_sfs = []\n",
        "# for i in range(n_scenario):\n",
        "#     model = random_pr_like_model(3)\n",
        "#     random_sfs.append(model.signalling_fraction())\n",
        "\n",
        "# plt.hist(random_sfs, bins=50)\n",
        "# plt.xlim((0,1))\n",
        "# plt.title(\"Signalling fractions from random models\")\n",
        "# plt.show()"
      ],
      "id": "tHJZK4HX73rk"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of pr_lang.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "063a30831d0846c2a30106ffb6c926bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df258f8e02a34aa9828e79a8f76cbb0a",
              "IPY_MODEL_5c7e31ec78c9434caae3cc0f8240655b",
              "IPY_MODEL_ac7b1dc80dca4df6babadb71dd3e50e4"
            ],
            "layout": "IPY_MODEL_93f4c83c284a48b29d038ca8f8d5cf8d"
          }
        },
        "df258f8e02a34aa9828e79a8f76cbb0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5a896e20b84461e8b7557280441c095",
            "placeholder": "​",
            "style": "IPY_MODEL_28f8b528248f4e8bbf9d574363f67886",
            "value": "100%"
          }
        },
        "5c7e31ec78c9434caae3cc0f8240655b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9171e3f8b59748709bb3270ecdecb52a",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4cce5931a70c4f9a91b6046cb7b11331",
            "value": 3
          }
        },
        "ac7b1dc80dca4df6babadb71dd3e50e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1adda4f9f5c245f88f29af431e8f6d36",
            "placeholder": "​",
            "style": "IPY_MODEL_acc4bc9cb2364046ab6aa03664fbb9b3",
            "value": " 3/3 [00:11&lt;00:00,  3.79s/it]"
          }
        },
        "93f4c83c284a48b29d038ca8f8d5cf8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5a896e20b84461e8b7557280441c095": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28f8b528248f4e8bbf9d574363f67886": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9171e3f8b59748709bb3270ecdecb52a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cce5931a70c4f9a91b6046cb7b11331": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1adda4f9f5c245f88f29af431e8f6d36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acc4bc9cb2364046ab6aa03664fbb9b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}